{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85d6ec18-f019-495c-b1de-93a2e2829291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a134eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def conv_3x3_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.identity = stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, width_multiplier=1., num_classes=1000):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # setting of inverted residual blocks\n",
    "        self.cfgs = [\n",
    "            # t, c, n, s\n",
    "            [1,  16, 1, 1],\n",
    "            [6,  24, 2, 2],\n",
    "            [6,  32, 3, 2],\n",
    "            [6,  64, 4, 2],\n",
    "            [6,  96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(32 * width_multiplier, 4 if width_multiplier == 0.1 else 8)\n",
    "        layers = [conv_3x3_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        block = InvertedResidual\n",
    "        for t, c, n, s in self.cfgs:\n",
    "            output_channel = _make_divisible(c * width_multiplier, 4 if width_multiplier == 0.1 else 8)\n",
    "            for i in range(n):\n",
    "                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t))\n",
    "                input_channel = output_channel\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        # building last several layers\n",
    "        output_channel = _make_divisible(1280 * width_multiplier, 4 if width_multiplier == 0.1 else 8) if width_multiplier > 1.0 else 1280\n",
    "        self.conv = conv_1x1_bn(input_channel, output_channel)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(output_channel, num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "603d647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "MobileNetV2                              --                        --\n",
      "├─Sequential: 1-1                        [1, 320, 7, 7]            --\n",
      "│    └─Sequential: 2-1                   [1, 32, 112, 112]         --\n",
      "│    │    └─Conv2d: 3-1                  [1, 32, 112, 112]         864\n",
      "│    │    └─BatchNorm2d: 3-2             [1, 32, 112, 112]         64\n",
      "│    │    └─ReLU6: 3-3                   [1, 32, 112, 112]         --\n",
      "│    └─InvertedResidual: 2-2             [1, 16, 112, 112]         --\n",
      "│    │    └─Sequential: 3-4              [1, 16, 112, 112]         896\n",
      "│    └─InvertedResidual: 2-3             [1, 24, 56, 56]           --\n",
      "│    │    └─Sequential: 3-5              [1, 24, 56, 56]           5,136\n",
      "│    └─InvertedResidual: 2-4             [1, 24, 56, 56]           --\n",
      "│    │    └─Sequential: 3-6              [1, 24, 56, 56]           8,832\n",
      "│    └─InvertedResidual: 2-5             [1, 32, 28, 28]           --\n",
      "│    │    └─Sequential: 3-7              [1, 32, 28, 28]           10,000\n",
      "│    └─InvertedResidual: 2-6             [1, 32, 28, 28]           --\n",
      "│    │    └─Sequential: 3-8              [1, 32, 28, 28]           14,848\n",
      "│    └─InvertedResidual: 2-7             [1, 32, 28, 28]           --\n",
      "│    │    └─Sequential: 3-9              [1, 32, 28, 28]           14,848\n",
      "│    └─InvertedResidual: 2-8             [1, 64, 14, 14]           --\n",
      "│    │    └─Sequential: 3-10             [1, 64, 14, 14]           21,056\n",
      "│    └─InvertedResidual: 2-9             [1, 64, 14, 14]           --\n",
      "│    │    └─Sequential: 3-11             [1, 64, 14, 14]           54,272\n",
      "│    └─InvertedResidual: 2-10            [1, 64, 14, 14]           --\n",
      "│    │    └─Sequential: 3-12             [1, 64, 14, 14]           54,272\n",
      "│    └─InvertedResidual: 2-11            [1, 64, 14, 14]           --\n",
      "│    │    └─Sequential: 3-13             [1, 64, 14, 14]           54,272\n",
      "│    └─InvertedResidual: 2-12            [1, 96, 14, 14]           --\n",
      "│    │    └─Sequential: 3-14             [1, 96, 14, 14]           66,624\n",
      "│    └─InvertedResidual: 2-13            [1, 96, 14, 14]           --\n",
      "│    │    └─Sequential: 3-15             [1, 96, 14, 14]           118,272\n",
      "│    └─InvertedResidual: 2-14            [1, 96, 14, 14]           --\n",
      "│    │    └─Sequential: 3-16             [1, 96, 14, 14]           118,272\n",
      "│    └─InvertedResidual: 2-15            [1, 160, 7, 7]            --\n",
      "│    │    └─Sequential: 3-17             [1, 160, 7, 7]            155,264\n",
      "│    └─InvertedResidual: 2-16            [1, 160, 7, 7]            --\n",
      "│    │    └─Sequential: 3-18             [1, 160, 7, 7]            320,000\n",
      "│    └─InvertedResidual: 2-17            [1, 160, 7, 7]            --\n",
      "│    │    └─Sequential: 3-19             [1, 160, 7, 7]            320,000\n",
      "│    └─InvertedResidual: 2-18            [1, 320, 7, 7]            --\n",
      "│    │    └─Sequential: 3-20             [1, 320, 7, 7]            473,920\n",
      "├─Sequential: 1-2                        [1, 1280, 7, 7]           --\n",
      "│    └─Conv2d: 2-19                      [1, 1280, 7, 7]           409,600\n",
      "│    └─BatchNorm2d: 2-20                 [1, 1280, 7, 7]           2,560\n",
      "│    └─ReLU6: 2-21                       [1, 1280, 7, 7]           --\n",
      "├─AdaptiveAvgPool2d: 1-3                 [1, 1280, 1, 1]           --\n",
      "├─Linear: 1-4                            [1, 10]                   12,810\n",
      "==========================================================================================\n",
      "Total params: 2,236,682\n",
      "Trainable params: 2,236,682\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 299.54\n",
      "==========================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 106.85\n",
      "Params size (MB): 8.95\n",
      "Estimated Total Size (MB): 116.40\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model = MobileNetV2(width_multiplier=1, num_classes=10).to(device)\n",
    "print(summary(model, input_size=(1, 3,224,224), verbose=0, depth=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da967f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f9d57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
