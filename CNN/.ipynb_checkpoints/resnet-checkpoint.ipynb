{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fea395-bddb-4ddc-aec2-d7c96112d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "966bcf05-6c9e-4892-89e4-a64115a31f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_18 = [2,2,2,2]\n",
    "layer_32 = [3,4,6,3]\n",
    "layer_50 = [3,4,6,3]\n",
    "layer_101 = [3,4,23,3]\n",
    "layer_152 = [3,8,36,3]\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1): #(int, int, int)\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1): #(int, int, int)\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None): #(int, int, int, NoneType)\n",
    "        super().__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride) # 3x3 kernel, stride=stride\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU() #inplace=True\n",
    "        self.conv2 = conv3x3(planes, planes) # 3x3 kernel, stride=1 고정\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        # 만약 여기서 padding=1 stride=2라면 kernel size에 의해 줄어들진않지만 \n",
    "        # stride에 의해 feature size가 반으로줄어들게됨(즉 downsampling)\n",
    "        out = self.conv1(x)  # 3x3 stride = 2\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)  # 3x3 stride = 2\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    # 각 conv의 마지막 layer에서 채널갯수가 4배로 뻥튀기됨\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv1x1(inplanes, planes) # 1x1 kernel, stride=1 고정\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride) # 3x3 kernel, stride=stride\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes*self.expansion) # 1x1 kernel, stride=1 고정, 채널 4배뻥튀기\n",
    "        self.bn3 = nn.BatchNorm2d(planes*self.expansion)\n",
    "        self.relu = nn.ReLU() #inplace=True\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x # initial input x\n",
    "\n",
    "        out = self.conv1(x) # 1층\n",
    "        out = self.bn1(out)\n",
    "\n",
    "        out = self.conv2(out) # 2층\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out) # 3층\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        # stride가 1이 아닌경우 또는 in_feature 사이즈와 out_feature size가 다른경우때(4배짜리 마지막레이어의경우!) None이아님.\n",
    "        # (stride 때문에 줄어든 feature map 연산을 가능하게 하기위해 downsample 을해줌)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity # 위에 3층의 레이어가 지난뒤 그전에 있던 x input을 더해줌 \n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79cba07d-8b46-4576-bf25-97c8cfd0a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    # model = ResNet(Bottleneck, [3,4,6,3], **kwargs) <- resnet 50\n",
    "    def __init__(self, block, layers, num_classes=10, zero_init_residual=False): #(class, list, int, bool)\n",
    "        super().__init__()\n",
    "        self.inplanes = 64\n",
    "        # inputs.shape = [3x224x224]\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3) # bias=False\n",
    "        # outputs = self.conv1(intput) -> outputs.shape = [64x112x112]\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU() #inplace=True\n",
    "        # inputs.shape = [64x112x112]\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # outputs.shape = [64x56x56]\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0]) # default: stride=1\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d([1, 1])\n",
    "        self.fc = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d): # 현재 단계의 모듈이 conv layer면 kaiming_normalization을 하고\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d): # 현재 단계의 모듈이 batch normalization이면 weight를 1로 bias를 0으로 바꿔줌\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck): # 모듈이 bottleneck일때 위에서선언한 BatchNorm2d(4배로 채널이 뻥튀기되는부분) weight를 0으로 초기화\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock): # 모듈이 BasicBlock일때 2번씩 반복하는 구간 마지막 레이어 weight를 0으로 초기화\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "        \n",
    "        # In Case of ResNet50\n",
    "        # self.layer1 = self._make_layer(block=Bottleneck, planes=64, blocks=3, stride=1)\n",
    "        # self.layer2 = self._make_layer(Bottleneck, 128, 4, stride=2)\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        # ie. stride가 1이 아니거나(or) sequential에서 마지막 layer의 output이 64가 아니면 downsampling 진행함(중간레이어)\n",
    "        if stride != 1 or self.inplanes != planes*block.expansion: # stride=1이맞지만 inplanes = 64 != 64*4 = 256\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes*block.expansion, stride), # conv1x1(64, 256, stride=1)로 만들어줌\n",
    "                nn.BatchNorm2d(planes*block.expansion), # BatchNorm2d(256)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample)) # layers.append(block(64, 64, 1, downsample))\n",
    "        self.inplanes = planes*block.expansion # self.inplanes = 64*4 = 256\n",
    "        for _ in range(1, blocks): # 여기서 블록갯수만큼 반복\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "        # self.layer1 = [\n",
    "        #                Bottleneck(in, out, stride, downsample) -> 1x1, 64 + 3x3, 64 + 1x1, 256 conv layer 가 총 n개 생성\n",
    "        #                Bottleneck(in, out)\n",
    "        #                Bottleneck(in, out)\n",
    "        #]\n",
    "        \n",
    "        # self.layer2 = [\n",
    "        #                Bottleneck(in, out, stride, downsample)\n",
    "        #                Bottleneck(in, out)\n",
    "        #                Bottleneck(in, out)\n",
    "        #]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7499c95f-69a1-4340-8cfd-bed64ef1f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(pretrained=False, **kwargs):\n",
    "    model = ResNet(BasicBlock, layer_18, **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnet32(pretrained=False, **kwargs):\n",
    "    model = ResNet(BasicBlock, layer_32, **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    model = ResNet(Bottleneck, layer_50, **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    model = ResNet(Bottleneck, layer_101, **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    model = ResNet(Bottleneck, layer_152, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e84ee96b-a807-49d3-8a4d-642fbad4a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18()\n",
    "# model = resnet32()\n",
    "# model = resnet50()\n",
    "# model = resnet101()\n",
    "# model = resnet152()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec57bcd-02b2-4bde-a61f-6b887e569b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 64, 112, 112]        9,472\n",
      "├─BatchNorm2d: 1-2                       [-1, 64, 112, 112]        128\n",
      "├─ReLU: 1-3                              [-1, 64, 112, 112]        --\n",
      "├─MaxPool2d: 1-4                         [-1, 64, 56, 56]          --\n",
      "├─Sequential: 1-5                        [-1, 64, 56, 56]          --\n",
      "|    └─BasicBlock: 2-1                   [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 56, 56]          36,864\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-3                    [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-4                  [-1, 64, 56, 56]          36,864\n",
      "|    |    └─BatchNorm2d: 3-5             [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-6                    [-1, 64, 56, 56]          --\n",
      "|    └─BasicBlock: 2-2                   [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 64, 56, 56]          36,864\n",
      "|    |    └─BatchNorm2d: 3-8             [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-9                    [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-10                 [-1, 64, 56, 56]          36,864\n",
      "|    |    └─BatchNorm2d: 3-11            [-1, 64, 56, 56]          128\n",
      "|    |    └─ReLU: 3-12                   [-1, 64, 56, 56]          --\n",
      "├─Sequential: 1-6                        [-1, 128, 28, 28]         --\n",
      "|    └─BasicBlock: 2-3                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 128, 28, 28]         73,728\n",
      "|    |    └─BatchNorm2d: 3-14            [-1, 128, 28, 28]         256\n",
      "|    |    └─ReLU: 3-15                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-16                 [-1, 128, 28, 28]         147,456\n",
      "|    |    └─BatchNorm2d: 3-17            [-1, 128, 28, 28]         256\n",
      "|    |    └─Sequential: 3-18             [-1, 128, 28, 28]         8,448\n",
      "|    |    └─ReLU: 3-19                   [-1, 128, 28, 28]         --\n",
      "|    └─BasicBlock: 2-4                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-20                 [-1, 128, 28, 28]         147,456\n",
      "|    |    └─BatchNorm2d: 3-21            [-1, 128, 28, 28]         256\n",
      "|    |    └─ReLU: 3-22                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-23                 [-1, 128, 28, 28]         147,456\n",
      "|    |    └─BatchNorm2d: 3-24            [-1, 128, 28, 28]         256\n",
      "|    |    └─ReLU: 3-25                   [-1, 128, 28, 28]         --\n",
      "├─Sequential: 1-7                        [-1, 256, 14, 14]         --\n",
      "|    └─BasicBlock: 2-5                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-26                 [-1, 256, 14, 14]         294,912\n",
      "|    |    └─BatchNorm2d: 3-27            [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-28                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-29                 [-1, 256, 14, 14]         589,824\n",
      "|    |    └─BatchNorm2d: 3-30            [-1, 256, 14, 14]         512\n",
      "|    |    └─Sequential: 3-31             [-1, 256, 14, 14]         33,280\n",
      "|    |    └─ReLU: 3-32                   [-1, 256, 14, 14]         --\n",
      "|    └─BasicBlock: 2-6                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-33                 [-1, 256, 14, 14]         589,824\n",
      "|    |    └─BatchNorm2d: 3-34            [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-35                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-36                 [-1, 256, 14, 14]         589,824\n",
      "|    |    └─BatchNorm2d: 3-37            [-1, 256, 14, 14]         512\n",
      "|    |    └─ReLU: 3-38                   [-1, 256, 14, 14]         --\n",
      "├─Sequential: 1-8                        [-1, 512, 7, 7]           --\n",
      "|    └─BasicBlock: 2-7                   [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-39                 [-1, 512, 7, 7]           1,179,648\n",
      "|    |    └─BatchNorm2d: 3-40            [-1, 512, 7, 7]           1,024\n",
      "|    |    └─ReLU: 3-41                   [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-42                 [-1, 512, 7, 7]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-43            [-1, 512, 7, 7]           1,024\n",
      "|    |    └─Sequential: 3-44             [-1, 512, 7, 7]           132,096\n",
      "|    |    └─ReLU: 3-45                   [-1, 512, 7, 7]           --\n",
      "|    └─BasicBlock: 2-8                   [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-46                 [-1, 512, 7, 7]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-47            [-1, 512, 7, 7]           1,024\n",
      "|    |    └─ReLU: 3-48                   [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-49                 [-1, 512, 7, 7]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-50            [-1, 512, 7, 7]           1,024\n",
      "|    |    └─ReLU: 3-51                   [-1, 512, 7, 7]           --\n",
      "├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --\n",
      "├─Linear: 1-10                           [-1, 10]                  5,130\n",
      "==========================================================================================\n",
      "Total params: 11,181,706\n",
      "Trainable params: 11,181,706\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.84\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 37.90\n",
      "Params size (MB): 42.65\n",
      "Estimated Total Size (MB): 81.13\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, input_data=(3, 224, 224), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93eb46-67ee-4c2a-afc0-31b329204c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
