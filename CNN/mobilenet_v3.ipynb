{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76c30af5-8fc2-4c4a-8346-75ff68d4025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e969303-1754-4f45-9920-198f6998f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "class ConvBNActivation(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_planes: int,\n",
    "        out_planes: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 1,\n",
    "        groups: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        activation_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        dilation: int = 1,\n",
    "    ) -> None:\n",
    "        padding = (kernel_size - 1) // 2 * dilation\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if activation_layer is None:\n",
    "            activation_layer = nn.ReLU6\n",
    "        super().__init__(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, dilation=dilation, groups=groups,\n",
    "                      bias=False),\n",
    "            norm_layer(out_planes),\n",
    "            activation_layer(inplace=True)\n",
    "        )\n",
    "        self.out_channels = out_planes\n",
    "\n",
    "        \n",
    "class SqueezeExcitation(nn.Module):\n",
    "    # Implemented as described at Figure 4 of the MobileNetV3 paper\n",
    "    def __init__(self, input_channels: int, squeeze_factor: int = 4):\n",
    "        super().__init__()\n",
    "        squeeze_channels = _make_divisible(input_channels // squeeze_factor, 8)\n",
    "        self.fc1 = nn.Conv2d(input_channels, squeeze_channels, 1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(squeeze_channels, input_channels, 1)\n",
    "\n",
    "    def _scale(self, input: Tensor, inplace: bool) -> Tensor:\n",
    "        scale = F.adaptive_avg_pool2d(input, 1)\n",
    "        scale = self.fc1(scale)\n",
    "        scale = self.relu(scale)\n",
    "        scale = self.fc2(scale)\n",
    "        return F.hardsigmoid(scale, inplace=inplace)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        scale = self._scale(input, True)\n",
    "        return scale * input\n",
    "\n",
    "    \n",
    "class InvertedResidualConfig:\n",
    "    # Stores information listed at Tables 1 and 2 of the MobileNetV3 paper\n",
    "    def __init__(self, input_channels: int, kernel: int, expanded_channels: int, out_channels: int, use_se: bool,\n",
    "                 activation: str, stride: int, dilation: int, width_mult: float):\n",
    "        self.input_channels = self.adjust_channels(input_channels, width_mult)\n",
    "        self.kernel = kernel\n",
    "        self.expanded_channels = self.adjust_channels(expanded_channels, width_mult)\n",
    "        self.out_channels = self.adjust_channels(out_channels, width_mult)\n",
    "        self.use_se = use_se\n",
    "        self.use_hs = activation == \"HS\"\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "    @staticmethod\n",
    "    def adjust_channels(channels: int, width_mult: float):\n",
    "        return _make_divisible(channels * width_mult, 8)\n",
    "\n",
    "    \n",
    "class InvertedResidual(nn.Module):\n",
    "    # Implemented as described at section 5 of MobileNetV3 paper\n",
    "    def __init__(self, cnf: InvertedResidualConfig, norm_layer: Callable[..., nn.Module],\n",
    "                 se_layer: Callable[..., nn.Module] = SqueezeExcitation):\n",
    "        super().__init__()\n",
    "        if not (1 <= cnf.stride <= 2):\n",
    "            raise ValueError('illegal stride value')\n",
    "\n",
    "        self.use_res_connect = cnf.stride == 1 and cnf.input_channels == cnf.out_channels\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        activation_layer = nn.Hardswish if cnf.use_hs else nn.ReLU\n",
    "\n",
    "        # expand\n",
    "        if cnf.expanded_channels != cnf.input_channels:\n",
    "            layers.append(ConvBNActivation(cnf.input_channels, cnf.expanded_channels, kernel_size=1,\n",
    "                                           norm_layer=norm_layer, activation_layer=activation_layer))\n",
    "\n",
    "        # depthwise\n",
    "        stride = 1 if cnf.dilation > 1 else cnf.stride\n",
    "        layers.append(ConvBNActivation(cnf.expanded_channels, cnf.expanded_channels, kernel_size=cnf.kernel,\n",
    "                                       stride=stride, dilation=cnf.dilation, groups=cnf.expanded_channels,\n",
    "                                       norm_layer=norm_layer, activation_layer=activation_layer))\n",
    "        if cnf.use_se:\n",
    "            layers.append(se_layer(cnf.expanded_channels))\n",
    "\n",
    "        # project\n",
    "        layers.append(ConvBNActivation(cnf.expanded_channels, cnf.out_channels, kernel_size=1, norm_layer=norm_layer,\n",
    "                                       activation_layer=nn.Identity))\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "        self.out_channels = cnf.out_channels\n",
    "        self._is_cn = cnf.stride > 1\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        result = self.block(input)\n",
    "        if self.use_res_connect:\n",
    "            result += input\n",
    "        return result\n",
    "\n",
    "\n",
    "class MobileNetV3(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            inverted_residual_setting: List[InvertedResidualConfig],\n",
    "            last_channel: int,\n",
    "            num_classes: int = 1000,\n",
    "            block: Optional[Callable[..., nn.Module]] = None,\n",
    "            norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "            **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        MobileNet V3 main class\n",
    "\n",
    "        Args:\n",
    "            inverted_residual_setting (List[InvertedResidualConfig]): Network structure\n",
    "            last_channel (int): The number of channels on the penultimate layer\n",
    "            num_classes (int): Number of classes\n",
    "            block (Optional[Callable[..., nn.Module]]): Module specifying inverted residual building block for mobilenet\n",
    "            norm_layer (Optional[Callable[..., nn.Module]]): Module specifying the normalization layer to use\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if not inverted_residual_setting:\n",
    "            raise ValueError(\"The inverted_residual_setting should not be empty\")\n",
    "        elif not (isinstance(inverted_residual_setting, Sequence) and\n",
    "                  all([isinstance(s, InvertedResidualConfig) for s in inverted_residual_setting])):\n",
    "            raise TypeError(\"The inverted_residual_setting should be List[InvertedResidualConfig]\")\n",
    "\n",
    "        if block is None:\n",
    "            block = InvertedResidual\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = partial(nn.BatchNorm2d, eps=0.001, momentum=0.01)\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "\n",
    "        # building first layer\n",
    "        firstconv_output_channels = inverted_residual_setting[0].input_channels\n",
    "        layers.append(ConvBNActivation(3, firstconv_output_channels, kernel_size=3, stride=2, norm_layer=norm_layer,\n",
    "                                       activation_layer=nn.Hardswish))\n",
    "\n",
    "        # building inverted residual blocks\n",
    "        for cnf in inverted_residual_setting:\n",
    "            layers.append(block(cnf, norm_layer))\n",
    "\n",
    "        # building last several layers\n",
    "        lastconv_input_channels = inverted_residual_setting[-1].out_channels\n",
    "        lastconv_output_channels = 6 * lastconv_input_channels\n",
    "        layers.append(ConvBNActivation(lastconv_input_channels, lastconv_output_channels, kernel_size=1,\n",
    "                                       norm_layer=norm_layer, activation_layer=nn.Hardswish))\n",
    "\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lastconv_output_channels, last_channel),\n",
    "            nn.Hardswish(inplace=True),\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(last_channel, num_classes),\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        x = self.features(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def _mobilenet_v3_conf(arch: str, width_mult: float = 1.0, reduced_tail: bool = False, dilated: bool = False,\n",
    "                       **kwargs: Any):\n",
    "    reduce_divider = 2 if reduced_tail else 1\n",
    "    dilation = 2 if dilated else 1\n",
    "\n",
    "    bneck_conf = partial(InvertedResidualConfig, width_mult=width_mult)\n",
    "    adjust_channels = partial(InvertedResidualConfig.adjust_channels, width_mult=width_mult)\n",
    "\n",
    "    if arch == \"mobilenet_v3_large\":\n",
    "        inverted_residual_setting = [\n",
    "            bneck_conf(16, 3, 16, 16, False, \"RE\", 1, 1),\n",
    "            bneck_conf(16, 3, 64, 24, False, \"RE\", 2, 1),  # C1\n",
    "            bneck_conf(24, 3, 72, 24, False, \"RE\", 1, 1),\n",
    "            bneck_conf(24, 5, 72, 40, True, \"RE\", 2, 1),  # C2\n",
    "            bneck_conf(40, 5, 120, 40, True, \"RE\", 1, 1),\n",
    "            bneck_conf(40, 5, 120, 40, True, \"RE\", 1, 1),\n",
    "            bneck_conf(40, 3, 240, 80, False, \"HS\", 2, 1),  # C3\n",
    "            bneck_conf(80, 3, 200, 80, False, \"HS\", 1, 1),\n",
    "            bneck_conf(80, 3, 184, 80, False, \"HS\", 1, 1),\n",
    "            bneck_conf(80, 3, 184, 80, False, \"HS\", 1, 1),\n",
    "            bneck_conf(80, 3, 480, 112, True, \"HS\", 1, 1),\n",
    "            bneck_conf(112, 3, 672, 112, True, \"HS\", 1, 1),\n",
    "            bneck_conf(112, 5, 672, 160 // reduce_divider, True, \"HS\", 2, dilation),  # C4\n",
    "            bneck_conf(160 // reduce_divider, 5, 960 // reduce_divider, 160 // reduce_divider, True, \"HS\", 1, dilation),\n",
    "            bneck_conf(160 // reduce_divider, 5, 960 // reduce_divider, 160 // reduce_divider, True, \"HS\", 1, dilation),\n",
    "        ]\n",
    "        last_channel = adjust_channels(1280 // reduce_divider)  # C5\n",
    "    elif arch == \"mobilenet_v3_small\":\n",
    "        inverted_residual_setting = [\n",
    "            bneck_conf(16, 3, 16, 16, True, \"RE\", 2, 1),  # C1\n",
    "            bneck_conf(16, 3, 72, 24, False, \"RE\", 2, 1),  # C2\n",
    "            bneck_conf(24, 3, 88, 24, False, \"RE\", 1, 1),\n",
    "            bneck_conf(24, 5, 96, 40, True, \"HS\", 2, 1),  # C3\n",
    "            bneck_conf(40, 5, 240, 40, True, \"HS\", 1, 1),\n",
    "            bneck_conf(40, 5, 240, 40, True, \"HS\", 1, 1),\n",
    "            bneck_conf(40, 5, 120, 48, True, \"HS\", 1, 1),\n",
    "            bneck_conf(48, 5, 144, 48, True, \"HS\", 1, 1),\n",
    "            bneck_conf(48, 5, 288, 96 // reduce_divider, True, \"HS\", 2, dilation),  # C4\n",
    "            bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, \"HS\", 1, dilation),\n",
    "            bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, \"HS\", 1, dilation),\n",
    "        ]\n",
    "        last_channel = adjust_channels(1024 // reduce_divider)  # C5\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type {}\".format(arch))\n",
    "\n",
    "    return inverted_residual_setting, last_channel\n",
    "\n",
    "\n",
    "def _mobilenet_v3_model(\n",
    "    arch: str,\n",
    "    inverted_residual_setting: List[InvertedResidualConfig],\n",
    "    last_channel: int,\n",
    "    progress: bool,\n",
    "    **kwargs: Any\n",
    "):\n",
    "    model = MobileNetV3(inverted_residual_setting, last_channel, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def mobilenet_v3_large(progress: bool = True, **kwargs: Any) -> MobileNetV3:\n",
    "    \"\"\"\n",
    "    Constructs a large MobileNetV3 architecture from\n",
    "    `\"Searching for MobileNetV3\" <https://arxiv.org/abs/1905.02244>`_.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    arch = \"mobilenet_v3_large\"\n",
    "    inverted_residual_setting, last_channel = _mobilenet_v3_conf(arch, **kwargs)\n",
    "    return _mobilenet_v3_model(arch, inverted_residual_setting, last_channel, progress, **kwargs)\n",
    "\n",
    "\n",
    "def mobilenet_v3_small(progress: bool = True, **kwargs: Any) -> MobileNetV3:\n",
    "    \"\"\"\n",
    "    Constructs a small MobileNetV3 architecture from\n",
    "    `\"Searching for MobileNetV3\" <https://arxiv.org/abs/1905.02244>`_.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    arch = \"mobilenet_v3_small\"\n",
    "    inverted_residual_setting, last_channel = _mobilenet_v3_conf(arch, **kwargs)\n",
    "    return _mobilenet_v3_model(arch, inverted_residual_setting, last_channel, progress, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ae424ae-bbb2-4a81-892c-de585fd7f5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "MobileNetV3                                   --                        --\n",
      "├─Sequential: 1-1                             [1, 576, 7, 7]            --\n",
      "│    └─ConvBNActivation: 2-1                  [1, 16, 112, 112]         --\n",
      "│    │    └─Conv2d: 3-1                       [1, 16, 112, 112]         432\n",
      "│    │    └─BatchNorm2d: 3-2                  [1, 16, 112, 112]         32\n",
      "│    │    └─Hardswish: 3-3                    [1, 16, 112, 112]         --\n",
      "│    └─InvertedResidual: 2-2                  [1, 16, 56, 56]           --\n",
      "│    │    └─Sequential: 3-4                   [1, 16, 56, 56]           --\n",
      "│    │    │    └─ConvBNActivation: 4-1        [1, 16, 56, 56]           176\n",
      "│    │    │    └─SqueezeExcitation: 4-2       [1, 16, 56, 56]           280\n",
      "│    │    │    └─ConvBNActivation: 4-3        [1, 16, 56, 56]           288\n",
      "│    └─InvertedResidual: 2-3                  [1, 24, 28, 28]           --\n",
      "│    │    └─Sequential: 3-5                   [1, 24, 28, 28]           --\n",
      "│    │    │    └─ConvBNActivation: 4-4        [1, 72, 56, 56]           1,296\n",
      "│    │    │    └─ConvBNActivation: 4-5        [1, 72, 28, 28]           792\n",
      "│    │    │    └─ConvBNActivation: 4-6        [1, 24, 28, 28]           1,776\n",
      "│    └─InvertedResidual: 2-4                  [1, 24, 28, 28]           --\n",
      "│    │    └─Sequential: 3-6                   [1, 24, 28, 28]           --\n",
      "│    │    │    └─ConvBNActivation: 4-7        [1, 88, 28, 28]           2,288\n",
      "│    │    │    └─ConvBNActivation: 4-8        [1, 88, 28, 28]           968\n",
      "│    │    │    └─ConvBNActivation: 4-9        [1, 24, 28, 28]           2,160\n",
      "│    └─InvertedResidual: 2-5                  [1, 40, 14, 14]           --\n",
      "│    │    └─Sequential: 3-7                   [1, 40, 14, 14]           --\n",
      "│    │    │    └─ConvBNActivation: 4-10       [1, 96, 28, 28]           2,496\n",
      "│    │    │    └─ConvBNActivation: 4-11       [1, 96, 14, 14]           2,592\n",
      "│    │    │    └─SqueezeExcitation: 4-12      [1, 96, 14, 14]           4,728\n",
      "│    │    │    └─ConvBNActivation: 4-13       [1, 40, 14, 14]           3,920\n",
      "│    └─InvertedResidual: 2-6                  [1, 40, 14, 14]           --\n",
      "│    │    └─Sequential: 3-8                   [1, 40, 14, 14]           --\n",
      "│    │    │    └─ConvBNActivation: 4-14       [1, 240, 14, 14]          10,080\n",
      "│    │    │    └─ConvBNActivation: 4-15       [1, 240, 14, 14]          6,480\n",
      "│    │    │    └─SqueezeExcitation: 4-16      [1, 240, 14, 14]          31,024\n",
      "│    │    │    └─ConvBNActivation: 4-17       [1, 40, 14, 14]           9,680\n",
      "│    └─InvertedResidual: 2-7                  [1, 40, 14, 14]           --\n",
      "│    │    └─Sequential: 3-9                   [1, 40, 14, 14]           --\n",
      "│    │    │    └─ConvBNActivation: 4-18       [1, 240, 14, 14]          10,080\n",
      "│    │    │    └─ConvBNActivation: 4-19       [1, 240, 14, 14]          6,480\n",
      "│    │    │    └─SqueezeExcitation: 4-20      [1, 240, 14, 14]          31,024\n",
      "│    │    │    └─ConvBNActivation: 4-21       [1, 40, 14, 14]           9,680\n",
      "│    └─InvertedResidual: 2-8                  [1, 48, 14, 14]           --\n",
      "│    │    └─Sequential: 3-10                  [1, 48, 14, 14]           --\n",
      "│    │    │    └─ConvBNActivation: 4-22       [1, 120, 14, 14]          5,040\n",
      "│    │    │    └─ConvBNActivation: 4-23       [1, 120, 14, 14]          3,240\n",
      "│    │    │    └─SqueezeExcitation: 4-24      [1, 120, 14, 14]          7,832\n",
      "│    │    │    └─ConvBNActivation: 4-25       [1, 48, 14, 14]           5,856\n",
      "│    └─InvertedResidual: 2-9                  [1, 48, 14, 14]           --\n",
      "│    │    └─Sequential: 3-11                  [1, 48, 14, 14]           --\n",
      "│    │    │    └─ConvBNActivation: 4-26       [1, 144, 14, 14]          7,200\n",
      "│    │    │    └─ConvBNActivation: 4-27       [1, 144, 14, 14]          3,888\n",
      "│    │    │    └─SqueezeExcitation: 4-28      [1, 144, 14, 14]          11,704\n",
      "│    │    │    └─ConvBNActivation: 4-29       [1, 48, 14, 14]           7,008\n",
      "│    └─InvertedResidual: 2-10                 [1, 96, 7, 7]             --\n",
      "│    │    └─Sequential: 3-12                  [1, 96, 7, 7]             --\n",
      "│    │    │    └─ConvBNActivation: 4-30       [1, 288, 14, 14]          14,400\n",
      "│    │    │    └─ConvBNActivation: 4-31       [1, 288, 7, 7]            7,776\n",
      "│    │    │    └─SqueezeExcitation: 4-32      [1, 288, 7, 7]            41,832\n",
      "│    │    │    └─ConvBNActivation: 4-33       [1, 96, 7, 7]             27,840\n",
      "│    └─InvertedResidual: 2-11                 [1, 96, 7, 7]             --\n",
      "│    │    └─Sequential: 3-13                  [1, 96, 7, 7]             --\n",
      "│    │    │    └─ConvBNActivation: 4-34       [1, 576, 7, 7]            56,448\n",
      "│    │    │    └─ConvBNActivation: 4-35       [1, 576, 7, 7]            15,552\n",
      "│    │    │    └─SqueezeExcitation: 4-36      [1, 576, 7, 7]            166,608\n",
      "│    │    │    └─ConvBNActivation: 4-37       [1, 96, 7, 7]             55,488\n",
      "│    └─InvertedResidual: 2-12                 [1, 96, 7, 7]             --\n",
      "│    │    └─Sequential: 3-14                  [1, 96, 7, 7]             --\n",
      "│    │    │    └─ConvBNActivation: 4-38       [1, 576, 7, 7]            56,448\n",
      "│    │    │    └─ConvBNActivation: 4-39       [1, 576, 7, 7]            15,552\n",
      "│    │    │    └─SqueezeExcitation: 4-40      [1, 576, 7, 7]            166,608\n",
      "│    │    │    └─ConvBNActivation: 4-41       [1, 96, 7, 7]             55,488\n",
      "│    └─ConvBNActivation: 2-13                 [1, 576, 7, 7]            --\n",
      "│    │    └─Conv2d: 3-15                      [1, 576, 7, 7]            55,296\n",
      "│    │    └─BatchNorm2d: 3-16                 [1, 576, 7, 7]            1,152\n",
      "│    │    └─Hardswish: 3-17                   [1, 576, 7, 7]            --\n",
      "├─AdaptiveAvgPool2d: 1-2                      [1, 576, 1, 1]            --\n",
      "├─Sequential: 1-3                             [1, 1000]                 --\n",
      "│    └─Linear: 2-14                           [1, 1024]                 590,848\n",
      "│    └─Hardswish: 2-15                        [1, 1024]                 --\n",
      "│    └─Dropout: 2-16                          [1, 1024]                 --\n",
      "│    └─Linear: 2-17                           [1, 1000]                 1,025,000\n",
      "===============================================================================================\n",
      "Total params: 2,542,856\n",
      "Trainable params: 2,542,856\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 56.53\n",
      "===============================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 22.64\n",
      "Params size (MB): 10.17\n",
      "Estimated Total Size (MB): 33.42\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model = mobilenet_v3_small().to(device)\n",
    "print(summary(model, input_size=(1, 3,224,224), verbose=0, depth=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "310457ac-0423-4163-afe1-222365e13512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "MobileNetV3                                   --                        --\n",
      "├─Sequential: 1-1                             [1, 960, 7, 7]            --\n",
      "│    └─ConvBNActivation: 2-1                  [1, 16, 112, 112]         --\n",
      "│    │    └─Conv2d: 3-1                       [1, 16, 112, 112]         432\n",
      "│    │    └─BatchNorm2d: 3-2                  [1, 16, 112, 112]         32\n",
      "│    │    └─Hardswish: 3-3                    [1, 16, 112, 112]         --\n",
      "│    └─InvertedResidual: 2-2                  [1, 16, 112, 112]         --\n",
      "│    │    └─Sequential: 3-4                   [1, 16, 112, 112]         --\n",
      "│    │    │    └─ConvBNActivation: 4-1        [1, 16, 112, 112]         --\n",
      "│    │    │    │    └─Conv2d: 5-1             [1, 16, 112, 112]         144\n",
      "│    │    │    │    └─BatchNorm2d: 5-2        [1, 16, 112, 112]         32\n",
      "│    │    │    │    └─ReLU: 5-3               [1, 16, 112, 112]         --\n",
      "│    │    │    └─ConvBNActivation: 4-2        [1, 16, 112, 112]         --\n",
      "│    │    │    │    └─Conv2d: 5-4             [1, 16, 112, 112]         256\n",
      "│    │    │    │    └─BatchNorm2d: 5-5        [1, 16, 112, 112]         32\n",
      "│    │    │    │    └─Identity: 5-6           [1, 16, 112, 112]         --\n",
      "│    └─InvertedResidual: 2-3                  [1, 24, 56, 56]           --\n",
      "│    │    └─Sequential: 3-5                   [1, 24, 56, 56]           --\n",
      "│    │    │    └─ConvBNActivation: 4-3        [1, 64, 112, 112]         --\n",
      "│    │    │    │    └─Conv2d: 5-7             [1, 64, 112, 112]         1,024\n",
      "│    │    │    │    └─BatchNorm2d: 5-8        [1, 64, 112, 112]         128\n",
      "│    │    │    │    └─ReLU: 5-9               [1, 64, 112, 112]         --\n",
      "│    │    │    └─ConvBNActivation: 4-4        [1, 64, 56, 56]           --\n",
      "│    │    │    │    └─Conv2d: 5-10            [1, 64, 56, 56]           576\n",
      "│    │    │    │    └─BatchNorm2d: 5-11       [1, 64, 56, 56]           128\n",
      "│    │    │    │    └─ReLU: 5-12              [1, 64, 56, 56]           --\n",
      "│    │    │    └─ConvBNActivation: 4-5        [1, 24, 56, 56]           --\n",
      "│    │    │    │    └─Conv2d: 5-13            [1, 24, 56, 56]           1,536\n",
      "│    │    │    │    └─BatchNorm2d: 5-14       [1, 24, 56, 56]           48\n",
      "│    │    │    │    └─Identity: 5-15          [1, 24, 56, 56]           --\n",
      "│    └─InvertedResidual: 2-4                  [1, 24, 56, 56]           --\n",
      "│    │    └─Sequential: 3-6                   [1, 24, 56, 56]           --\n",
      "│    │    │    └─ConvBNActivation: 4-6        [1, 72, 56, 56]           --\n",
      "│    │    │    │    └─Conv2d: 5-16            [1, 72, 56, 56]           1,728\n",
      "│    │    │    │    └─BatchNorm2d: 5-17       [1, 72, 56, 56]           144\n",
      "│    │    │    │    └─ReLU: 5-18              [1, 72, 56, 56]           --\n",
      "│    │    │    └─ConvBNActivation: 4-7        [1, 72, 56, 56]           --\n",
      "│    │    │    │    └─Conv2d: 5-19            [1, 72, 56, 56]           648\n",
      "│    │    │    │    └─BatchNorm2d: 5-20       [1, 72, 56, 56]           144\n",
      "│    │    │    │    └─ReLU: 5-21              [1, 72, 56, 56]           --\n",
      "│    │    │    └─ConvBNActivation: 4-8        [1, 24, 56, 56]           --\n",
      "│    │    │    │    └─Conv2d: 5-22            [1, 24, 56, 56]           1,728\n",
      "│    │    │    │    └─BatchNorm2d: 5-23       [1, 24, 56, 56]           48\n",
      "│    │    │    │    └─Identity: 5-24          [1, 24, 56, 56]           --\n",
      "│    └─InvertedResidual: 2-5                  [1, 40, 28, 28]           --\n",
      "│    │    └─Sequential: 3-7                   [1, 40, 28, 28]           --\n",
      "│    │    │    └─ConvBNActivation: 4-9        [1, 72, 56, 56]           --\n",
      "│    │    │    │    └─Conv2d: 5-25            [1, 72, 56, 56]           1,728\n",
      "│    │    │    │    └─BatchNorm2d: 5-26       [1, 72, 56, 56]           144\n",
      "│    │    │    │    └─ReLU: 5-27              [1, 72, 56, 56]           --\n",
      "│    │    │    └─ConvBNActivation: 4-10       [1, 72, 28, 28]           --\n",
      "│    │    │    │    └─Conv2d: 5-28            [1, 72, 28, 28]           1,800\n",
      "│    │    │    │    └─BatchNorm2d: 5-29       [1, 72, 28, 28]           144\n",
      "│    │    │    │    └─ReLU: 5-30              [1, 72, 28, 28]           --\n",
      "│    │    │    └─SqueezeExcitation: 4-11      [1, 72, 28, 28]           --\n",
      "│    │    │    │    └─Conv2d: 5-31            [1, 24, 1, 1]             1,752\n",
      "│    │    │    │    └─ReLU: 5-32              [1, 24, 1, 1]             --\n",
      "│    │    │    │    └─Conv2d: 5-33            [1, 72, 1, 1]             1,800\n",
      "│    │    │    └─ConvBNActivation: 4-12       [1, 40, 28, 28]           --\n",
      "│    │    │    │    └─Conv2d: 5-34            [1, 40, 28, 28]           2,880\n",
      "│    │    │    │    └─BatchNorm2d: 5-35       [1, 40, 28, 28]           80\n",
      "│    │    │    │    └─Identity: 5-36          [1, 40, 28, 28]           --\n",
      "│    └─InvertedResidual: 2-6                  [1, 40, 28, 28]           --\n",
      "│    │    └─Sequential: 3-8                   [1, 40, 28, 28]           --\n",
      "│    │    │    └─ConvBNActivation: 4-13       [1, 120, 28, 28]          --\n",
      "│    │    │    │    └─Conv2d: 5-37            [1, 120, 28, 28]          4,800\n",
      "│    │    │    │    └─BatchNorm2d: 5-38       [1, 120, 28, 28]          240\n",
      "│    │    │    │    └─ReLU: 5-39              [1, 120, 28, 28]          --\n",
      "│    │    │    └─ConvBNActivation: 4-14       [1, 120, 28, 28]          --\n",
      "│    │    │    │    └─Conv2d: 5-40            [1, 120, 28, 28]          3,000\n",
      "│    │    │    │    └─BatchNorm2d: 5-41       [1, 120, 28, 28]          240\n",
      "│    │    │    │    └─ReLU: 5-42              [1, 120, 28, 28]          --\n",
      "│    │    │    └─SqueezeExcitation: 4-15      [1, 120, 28, 28]          --\n",
      "│    │    │    │    └─Conv2d: 5-43            [1, 32, 1, 1]             3,872\n",
      "│    │    │    │    └─ReLU: 5-44              [1, 32, 1, 1]             --\n",
      "│    │    │    │    └─Conv2d: 5-45            [1, 120, 1, 1]            3,960\n",
      "│    │    │    └─ConvBNActivation: 4-16       [1, 40, 28, 28]           --\n",
      "│    │    │    │    └─Conv2d: 5-46            [1, 40, 28, 28]           4,800\n",
      "│    │    │    │    └─BatchNorm2d: 5-47       [1, 40, 28, 28]           80\n",
      "│    │    │    │    └─Identity: 5-48          [1, 40, 28, 28]           --\n",
      "│    └─InvertedResidual: 2-7                  [1, 40, 28, 28]           --\n",
      "│    │    └─Sequential: 3-9                   [1, 40, 28, 28]           --\n",
      "│    │    │    └─ConvBNActivation: 4-17       [1, 120, 28, 28]          --\n",
      "│    │    │    │    └─Conv2d: 5-49            [1, 120, 28, 28]          4,800\n",
      "│    │    │    │    └─BatchNorm2d: 5-50       [1, 120, 28, 28]          240\n",
      "│    │    │    │    └─ReLU: 5-51              [1, 120, 28, 28]          --\n",
      "│    │    │    └─ConvBNActivation: 4-18       [1, 120, 28, 28]          --\n",
      "│    │    │    │    └─Conv2d: 5-52            [1, 120, 28, 28]          3,000\n",
      "│    │    │    │    └─BatchNorm2d: 5-53       [1, 120, 28, 28]          240\n",
      "│    │    │    │    └─ReLU: 5-54              [1, 120, 28, 28]          --\n",
      "│    │    │    └─SqueezeExcitation: 4-19      [1, 120, 28, 28]          --\n",
      "│    │    │    │    └─Conv2d: 5-55            [1, 32, 1, 1]             3,872\n",
      "│    │    │    │    └─ReLU: 5-56              [1, 32, 1, 1]             --\n",
      "│    │    │    │    └─Conv2d: 5-57            [1, 120, 1, 1]            3,960\n",
      "│    │    │    └─ConvBNActivation: 4-20       [1, 40, 28, 28]           --\n",
      "│    │    │    │    └─Conv2d: 5-58            [1, 40, 28, 28]           4,800\n",
      "│    │    │    │    └─BatchNorm2d: 5-59       [1, 40, 28, 28]           80\n",
      "│    │    │    │    └─Identity: 5-60          [1, 40, 28, 28]           --\n",
      "│    └─InvertedResidual: 2-8                  [1, 80, 14, 14]           --\n",
      "│    │    └─Sequential: 3-10                  [1, 80, 14, 14]           --\n",
      "│    │    │    └─ConvBNActivation: 4-21       [1, 240, 28, 28]          --\n",
      "│    │    │    │    └─Conv2d: 5-61            [1, 240, 28, 28]          9,600\n",
      "│    │    │    │    └─BatchNorm2d: 5-62       [1, 240, 28, 28]          480\n",
      "│    │    │    │    └─Hardswish: 5-63         [1, 240, 28, 28]          --\n",
      "│    │    │    └─ConvBNActivation: 4-22       [1, 240, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-64            [1, 240, 14, 14]          2,160\n",
      "│    │    │    │    └─BatchNorm2d: 5-65       [1, 240, 14, 14]          480\n",
      "│    │    │    │    └─Hardswish: 5-66         [1, 240, 14, 14]          --\n",
      "│    │    │    └─ConvBNActivation: 4-23       [1, 80, 14, 14]           --\n",
      "│    │    │    │    └─Conv2d: 5-67            [1, 80, 14, 14]           19,200\n",
      "│    │    │    │    └─BatchNorm2d: 5-68       [1, 80, 14, 14]           160\n",
      "│    │    │    │    └─Identity: 5-69          [1, 80, 14, 14]           --\n",
      "│    └─InvertedResidual: 2-9                  [1, 80, 14, 14]           --\n",
      "│    │    └─Sequential: 3-11                  [1, 80, 14, 14]           --\n",
      "│    │    │    └─ConvBNActivation: 4-24       [1, 200, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-70            [1, 200, 14, 14]          16,000\n",
      "│    │    │    │    └─BatchNorm2d: 5-71       [1, 200, 14, 14]          400\n",
      "│    │    │    │    └─Hardswish: 5-72         [1, 200, 14, 14]          --\n",
      "│    │    │    └─ConvBNActivation: 4-25       [1, 200, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-73            [1, 200, 14, 14]          1,800\n",
      "│    │    │    │    └─BatchNorm2d: 5-74       [1, 200, 14, 14]          400\n",
      "│    │    │    │    └─Hardswish: 5-75         [1, 200, 14, 14]          --\n",
      "│    │    │    └─ConvBNActivation: 4-26       [1, 80, 14, 14]           --\n",
      "│    │    │    │    └─Conv2d: 5-76            [1, 80, 14, 14]           16,000\n",
      "│    │    │    │    └─BatchNorm2d: 5-77       [1, 80, 14, 14]           160\n",
      "│    │    │    │    └─Identity: 5-78          [1, 80, 14, 14]           --\n",
      "│    └─InvertedResidual: 2-10                 [1, 80, 14, 14]           --\n",
      "│    │    └─Sequential: 3-12                  [1, 80, 14, 14]           --\n",
      "│    │    │    └─ConvBNActivation: 4-27       [1, 184, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-79            [1, 184, 14, 14]          14,720\n",
      "│    │    │    │    └─BatchNorm2d: 5-80       [1, 184, 14, 14]          368\n",
      "│    │    │    │    └─Hardswish: 5-81         [1, 184, 14, 14]          --\n",
      "│    │    │    └─ConvBNActivation: 4-28       [1, 184, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-82            [1, 184, 14, 14]          1,656\n",
      "│    │    │    │    └─BatchNorm2d: 5-83       [1, 184, 14, 14]          368\n",
      "│    │    │    │    └─Hardswish: 5-84         [1, 184, 14, 14]          --\n",
      "│    │    │    └─ConvBNActivation: 4-29       [1, 80, 14, 14]           --\n",
      "│    │    │    │    └─Conv2d: 5-85            [1, 80, 14, 14]           14,720\n",
      "│    │    │    │    └─BatchNorm2d: 5-86       [1, 80, 14, 14]           160\n",
      "│    │    │    │    └─Identity: 5-87          [1, 80, 14, 14]           --\n",
      "│    └─InvertedResidual: 2-11                 [1, 80, 14, 14]           --\n",
      "│    │    └─Sequential: 3-13                  [1, 80, 14, 14]           --\n",
      "│    │    │    └─ConvBNActivation: 4-30       [1, 184, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-88            [1, 184, 14, 14]          14,720\n",
      "│    │    │    │    └─BatchNorm2d: 5-89       [1, 184, 14, 14]          368\n",
      "│    │    │    │    └─Hardswish: 5-90         [1, 184, 14, 14]          --\n",
      "│    │    │    └─ConvBNActivation: 4-31       [1, 184, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-91            [1, 184, 14, 14]          1,656\n",
      "│    │    │    │    └─BatchNorm2d: 5-92       [1, 184, 14, 14]          368\n",
      "│    │    │    │    └─Hardswish: 5-93         [1, 184, 14, 14]          --\n",
      "│    │    │    └─ConvBNActivation: 4-32       [1, 80, 14, 14]           --\n",
      "│    │    │    │    └─Conv2d: 5-94            [1, 80, 14, 14]           14,720\n",
      "│    │    │    │    └─BatchNorm2d: 5-95       [1, 80, 14, 14]           160\n",
      "│    │    │    │    └─Identity: 5-96          [1, 80, 14, 14]           --\n",
      "│    └─InvertedResidual: 2-12                 [1, 112, 14, 14]          --\n",
      "│    │    └─Sequential: 3-14                  [1, 112, 14, 14]          --\n",
      "│    │    │    └─ConvBNActivation: 4-33       [1, 480, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-97            [1, 480, 14, 14]          38,400\n",
      "│    │    │    │    └─BatchNorm2d: 5-98       [1, 480, 14, 14]          960\n",
      "│    │    │    │    └─Hardswish: 5-99         [1, 480, 14, 14]          --\n",
      "│    │    │    └─ConvBNActivation: 4-34       [1, 480, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-100           [1, 480, 14, 14]          4,320\n",
      "│    │    │    │    └─BatchNorm2d: 5-101      [1, 480, 14, 14]          960\n",
      "│    │    │    │    └─Hardswish: 5-102        [1, 480, 14, 14]          --\n",
      "│    │    │    └─SqueezeExcitation: 4-35      [1, 480, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-103           [1, 120, 1, 1]            57,720\n",
      "│    │    │    │    └─ReLU: 5-104             [1, 120, 1, 1]            --\n",
      "│    │    │    │    └─Conv2d: 5-105           [1, 480, 1, 1]            58,080\n",
      "│    │    │    └─ConvBNActivation: 4-36       [1, 112, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-106           [1, 112, 14, 14]          53,760\n",
      "│    │    │    │    └─BatchNorm2d: 5-107      [1, 112, 14, 14]          224\n",
      "│    │    │    │    └─Identity: 5-108         [1, 112, 14, 14]          --\n",
      "│    └─InvertedResidual: 2-13                 [1, 112, 14, 14]          --\n",
      "│    │    └─Sequential: 3-15                  [1, 112, 14, 14]          --\n",
      "│    │    │    └─ConvBNActivation: 4-37       [1, 672, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-109           [1, 672, 14, 14]          75,264\n",
      "│    │    │    │    └─BatchNorm2d: 5-110      [1, 672, 14, 14]          1,344\n",
      "│    │    │    │    └─Hardswish: 5-111        [1, 672, 14, 14]          --\n",
      "│    │    │    └─ConvBNActivation: 4-38       [1, 672, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-112           [1, 672, 14, 14]          6,048\n",
      "│    │    │    │    └─BatchNorm2d: 5-113      [1, 672, 14, 14]          1,344\n",
      "│    │    │    │    └─Hardswish: 5-114        [1, 672, 14, 14]          --\n",
      "│    │    │    └─SqueezeExcitation: 4-39      [1, 672, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-115           [1, 168, 1, 1]            113,064\n",
      "│    │    │    │    └─ReLU: 5-116             [1, 168, 1, 1]            --\n",
      "│    │    │    │    └─Conv2d: 5-117           [1, 672, 1, 1]            113,568\n",
      "│    │    │    └─ConvBNActivation: 4-40       [1, 112, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-118           [1, 112, 14, 14]          75,264\n",
      "│    │    │    │    └─BatchNorm2d: 5-119      [1, 112, 14, 14]          224\n",
      "│    │    │    │    └─Identity: 5-120         [1, 112, 14, 14]          --\n",
      "│    └─InvertedResidual: 2-14                 [1, 160, 7, 7]            --\n",
      "│    │    └─Sequential: 3-16                  [1, 160, 7, 7]            --\n",
      "│    │    │    └─ConvBNActivation: 4-41       [1, 672, 14, 14]          --\n",
      "│    │    │    │    └─Conv2d: 5-121           [1, 672, 14, 14]          75,264\n",
      "│    │    │    │    └─BatchNorm2d: 5-122      [1, 672, 14, 14]          1,344\n",
      "│    │    │    │    └─Hardswish: 5-123        [1, 672, 14, 14]          --\n",
      "│    │    │    └─ConvBNActivation: 4-42       [1, 672, 7, 7]            --\n",
      "│    │    │    │    └─Conv2d: 5-124           [1, 672, 7, 7]            16,800\n",
      "│    │    │    │    └─BatchNorm2d: 5-125      [1, 672, 7, 7]            1,344\n",
      "│    │    │    │    └─Hardswish: 5-126        [1, 672, 7, 7]            --\n",
      "│    │    │    └─SqueezeExcitation: 4-43      [1, 672, 7, 7]            --\n",
      "│    │    │    │    └─Conv2d: 5-127           [1, 168, 1, 1]            113,064\n",
      "│    │    │    │    └─ReLU: 5-128             [1, 168, 1, 1]            --\n",
      "│    │    │    │    └─Conv2d: 5-129           [1, 672, 1, 1]            113,568\n",
      "│    │    │    └─ConvBNActivation: 4-44       [1, 160, 7, 7]            --\n",
      "│    │    │    │    └─Conv2d: 5-130           [1, 160, 7, 7]            107,520\n",
      "│    │    │    │    └─BatchNorm2d: 5-131      [1, 160, 7, 7]            320\n",
      "│    │    │    │    └─Identity: 5-132         [1, 160, 7, 7]            --\n",
      "│    └─InvertedResidual: 2-15                 [1, 160, 7, 7]            --\n",
      "│    │    └─Sequential: 3-17                  [1, 160, 7, 7]            --\n",
      "│    │    │    └─ConvBNActivation: 4-45       [1, 960, 7, 7]            --\n",
      "│    │    │    │    └─Conv2d: 5-133           [1, 960, 7, 7]            153,600\n",
      "│    │    │    │    └─BatchNorm2d: 5-134      [1, 960, 7, 7]            1,920\n",
      "│    │    │    │    └─Hardswish: 5-135        [1, 960, 7, 7]            --\n",
      "│    │    │    └─ConvBNActivation: 4-46       [1, 960, 7, 7]            --\n",
      "│    │    │    │    └─Conv2d: 5-136           [1, 960, 7, 7]            24,000\n",
      "│    │    │    │    └─BatchNorm2d: 5-137      [1, 960, 7, 7]            1,920\n",
      "│    │    │    │    └─Hardswish: 5-138        [1, 960, 7, 7]            --\n",
      "│    │    │    └─SqueezeExcitation: 4-47      [1, 960, 7, 7]            --\n",
      "│    │    │    │    └─Conv2d: 5-139           [1, 240, 1, 1]            230,640\n",
      "│    │    │    │    └─ReLU: 5-140             [1, 240, 1, 1]            --\n",
      "│    │    │    │    └─Conv2d: 5-141           [1, 960, 1, 1]            231,360\n",
      "│    │    │    └─ConvBNActivation: 4-48       [1, 160, 7, 7]            --\n",
      "│    │    │    │    └─Conv2d: 5-142           [1, 160, 7, 7]            153,600\n",
      "│    │    │    │    └─BatchNorm2d: 5-143      [1, 160, 7, 7]            320\n",
      "│    │    │    │    └─Identity: 5-144         [1, 160, 7, 7]            --\n",
      "│    └─InvertedResidual: 2-16                 [1, 160, 7, 7]            --\n",
      "│    │    └─Sequential: 3-18                  [1, 160, 7, 7]            --\n",
      "│    │    │    └─ConvBNActivation: 4-49       [1, 960, 7, 7]            --\n",
      "│    │    │    │    └─Conv2d: 5-145           [1, 960, 7, 7]            153,600\n",
      "│    │    │    │    └─BatchNorm2d: 5-146      [1, 960, 7, 7]            1,920\n",
      "│    │    │    │    └─Hardswish: 5-147        [1, 960, 7, 7]            --\n",
      "│    │    │    └─ConvBNActivation: 4-50       [1, 960, 7, 7]            --\n",
      "│    │    │    │    └─Conv2d: 5-148           [1, 960, 7, 7]            24,000\n",
      "│    │    │    │    └─BatchNorm2d: 5-149      [1, 960, 7, 7]            1,920\n",
      "│    │    │    │    └─Hardswish: 5-150        [1, 960, 7, 7]            --\n",
      "│    │    │    └─SqueezeExcitation: 4-51      [1, 960, 7, 7]            --\n",
      "│    │    │    │    └─Conv2d: 5-151           [1, 240, 1, 1]            230,640\n",
      "│    │    │    │    └─ReLU: 5-152             [1, 240, 1, 1]            --\n",
      "│    │    │    │    └─Conv2d: 5-153           [1, 960, 1, 1]            231,360\n",
      "│    │    │    └─ConvBNActivation: 4-52       [1, 160, 7, 7]            --\n",
      "│    │    │    │    └─Conv2d: 5-154           [1, 160, 7, 7]            153,600\n",
      "│    │    │    │    └─BatchNorm2d: 5-155      [1, 160, 7, 7]            320\n",
      "│    │    │    │    └─Identity: 5-156         [1, 160, 7, 7]            --\n",
      "│    └─ConvBNActivation: 2-17                 [1, 960, 7, 7]            --\n",
      "│    │    └─Conv2d: 3-19                      [1, 960, 7, 7]            153,600\n",
      "│    │    └─BatchNorm2d: 3-20                 [1, 960, 7, 7]            1,920\n",
      "│    │    └─Hardswish: 3-21                   [1, 960, 7, 7]            --\n",
      "├─AdaptiveAvgPool2d: 1-2                      [1, 960, 1, 1]            --\n",
      "├─Sequential: 1-3                             [1, 1000]                 --\n",
      "│    └─Linear: 2-18                           [1, 1280]                 1,230,080\n",
      "│    └─Hardswish: 2-19                        [1, 1280]                 --\n",
      "│    └─Dropout: 2-20                          [1, 1280]                 --\n",
      "│    └─Linear: 2-21                           [1, 1000]                 1,281,000\n",
      "===============================================================================================\n",
      "Total params: 5,483,032\n",
      "Trainable params: 5,483,032\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 216.62\n",
      "===============================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 70.46\n",
      "Params size (MB): 21.93\n",
      "Estimated Total Size (MB): 92.99\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = mobilenet_v3_large().to(device)\n",
    "print(summary(model, input_size=(1, 3,224,224), verbose=0, depth=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b4f28-80f0-42fa-87b4-bdf5b170a6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
